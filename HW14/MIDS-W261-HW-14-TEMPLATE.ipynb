{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS - w261 Machine Learning At Scale \n",
    "__Course Lead:__ Dr James G. Shanahan (__email__ Jimi via  James.Shanahan _AT_ gmail.com)\n",
    "\n",
    "## Week 14: Optional HW Assignment\n",
    "\n",
    "---\n",
    "__Name:__  *Your Name Goes Here*   \n",
    "__Class:__ MIDS w261 (Section *Your Section Goes Here*, e.g., Fall 2016 Group 1)     \n",
    "__Email:__  *Your UC Berkeley Email Goes Here*@iSchool.Berkeley.edu     \n",
    "__StudentId__  123457    __End of StudentId__     \n",
    "__Week:__   12\n",
    "\n",
    "__NOTE:__ please replace `1234567` with your student id above      \n",
    "__Due Time:__ HW is due by 8AM (West coast time). I.e., Friday, April 21, 2017 in the case of this homework. \n",
    "\n",
    "# Instructions\n",
    "\n",
    "MIDS UC Berkeley, Machine Learning at Scale   \n",
    "-----------------------\n",
    "V3.0 Final 4/21/2017  HW14\n",
    "-----------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SPECIAL INSTURCTIONS\n",
    "\n",
    "If possible try to complete HW14 using Zeppelin notebooks.\n",
    "\n",
    "Use Zeppelin viewer to share your notebooks\n",
    "https://www.zeppelinhub.com/viewer\n",
    "\n",
    "Here is a sample working Zeppelin notebook viewer link :\n",
    "\n",
    "https://www.zeppelinhub.com/viewer/notebooks/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL21lYWJoaXNoZWtrdW1hci96ZXBwZWxpbl9ub3RlYm9va3MvbWFzdGVyLzJCSFZDRzJBRS9ub3RlLmpzb24\n",
    "\n",
    "\n",
    "HW14 will need the cloud PAAS. Please divide and conquer the workload!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 14.1: Spark implementation of basic PageRank\n",
    "\n",
    "Write a basic Spark implementation of the iterative PageRank algorithm\n",
    "that takes sparse adjacency lists as input.\n",
    "Make sure that your implementation utilizes teleportation (1-damping/the number of nodes in the network), \n",
    "and further, distributes the mass of dangling nodes with each iteration\n",
    "so that the output of each iteration is correctly normalized (sums to 1).\n",
    "[NOTE: The PageRank algorithm assumes that a random surfer (walker), starting from a random web page,\n",
    "chooses the next page to which it will move by clicking at random, with probability d,\n",
    "one of the hyperlinks in the current page. This probability is represented by a so-called\n",
    "‘damping factor’ d, where d ∈ (0, 1). Otherwise, with probability (1 − d), the surfer\n",
    "jumps to any web page in the network. If a page is a dangling end, meaning it has no\n",
    "outgoing hyperlinks, the random surfer selects an arbitrary web page from a uniform\n",
    "distribution and “teleports” to that page]\n",
    "\n",
    "In your Spark solution, please use broadcast variables and caching to make sure your code is as efficient as possible.\n",
    "\n",
    "\n",
    "As you build your code, use the test data\n",
    "\n",
    "s3://ucb-mids-mls-networks/PageRank-test.txt\n",
    "Or under the Data Subfolder for HW7 on Dropbox with the same file name. \n",
    "(On Dropbox https://www.dropbox.com/sh/2c0k5adwz36lkcw/AAAAKsjQfF9uHfv-X9mCqr9wa?dl=0)\n",
    "\n",
    "with teleportation parameter set to 0.15 (1-d, where d, the damping factor is set to 0.85), and crosscheck\n",
    "your work with the true result, displayed in the first image\n",
    "in the Wikipedia article:\n",
    "\n",
    "https://en.wikipedia.org/wiki/PageRank\n",
    "\n",
    "and here for reference are the corresponding PageRank probabilities:\n",
    "```\n",
    "A,0.033\n",
    "B,0.384\n",
    "C,0.343\n",
    "D,0.039\n",
    "E,0.081\n",
    "F,0.039\n",
    "G,0.016\n",
    "H,0.016\n",
    "I,0.016\n",
    "J,0.016\n",
    "K,0.016\n",
    "```\n",
    "Run this experiment locally first. Report the local configuration that you used and how long in minutes and seconds it takes to complete your job.\n",
    "\n",
    "Repeat this experiment on AWS. Report the AWS cluster configuration that you used and how long in minutes and seconds it takes to complete your job. (in your notebook, cat the cluster config file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 14.2: Applying PageRank to the Wikipedia hyperlinks network===\n",
    "\n",
    "Run your Spark PageRank implementation on the Wikipedia dataset for 10 iterations,\n",
    "and display the top 100 ranked nodes (with alpha = 0.85).\n",
    "\n",
    "Run your PageRank implementation on the Wikipedia dataset for 50 iterations,\n",
    "and display the top 100 ranked nodes (with teleportation factor of 0.15). \n",
    "Plot the pagerank values for the top 100 pages resulting from the 50 iterations run. Then plot the pagerank values for the same 100 pages that resulted from the 10 iterations run.  Comment on your findings.  Have the top 100 ranked pages changed? Have the pagerank values changed? Explain.\n",
    "\n",
    "Report the AWS cluster configuration that you used and how long in minutes and seconds it takes to complete your job.\n",
    "\n",
    "NOTE: ====  English Wikipedia hyperlink network.data ====\n",
    "The dataset is available via Dropbox at:\n",
    "\n",
    "https://www.dropbox.com/sh/2c0k5adwz36lkcw/AAAAKsjQfF9uHfv-X9mCqr9wa?dl=0\n",
    "\n",
    "on S3 at  \n",
    "```\n",
    "s3://ucb-mids-mls-networks/wikipedia/\n",
    "-- s3://ucb-mids-mls-networks/wikipedia/all-pages-indexed-out.txt # Graph\n",
    "-- s3://ucb-mids-mls-networks/wikipedia/indices.txt               # Page titles and page Ids\n",
    "```\n",
    "The dataset is built from the Sept. 2015 XML snapshot of English Wikipedia.\n",
    "For this directed network, a link between articles: \n",
    "```\n",
    "A -> B\n",
    "```\n",
    "is defined by the existence of a hyperlink in A pointing to B.\n",
    "This network also exists in the indexed format:\n",
    "```\n",
    "Data: s3://ucb-mids-mls-networks/wikipedia/all-pages-indexed-out.txt\n",
    "Data: s3://ucb-mids-mls-networks/wikipedia/all-pages-indexed-in.txt\n",
    "Data: s3://ucb-mids-mls-networks/wikipedia/indices.txt\n",
    "```\n",
    "but has an index with more detailed data:\n",
    "\n",
    "(article name) \\t (index) \\t (in degree) \\t (out degree)\n",
    "\n",
    "In the dictionary, target nodes are keys, link weights are values .\n",
    "Here, a weight indicates the number of time a page links to another.\n",
    "However, for the sake of this assignment, treat this an unweighted network,\n",
    "and set all weights to 1 upon data input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 14.3: Spark GraphX versus your implementation of PageRank ===\n",
    "\n",
    "Run the Spark  GraphX PageRank implementation on the Wikipedia dataset for 10 iterations,\n",
    "and display the top 100 ranked nodes (with alpha = 0.85).\n",
    "\n",
    "Run your PageRank implementation on the Wikipedia dataset for 50 iterations,\n",
    "and display the top 100 ranked nodes (with teleportation factor of 0.15). \n",
    "Have the top 100 ranked pages changed? Comment on your findings. Plot both 100 curves.\n",
    "\n",
    "Report the AWS cluster configuration that you used and how long in minutes and seconds it takes to complete this job.\n",
    "\n",
    "Put the runtime results of HW13.2 and HW13.3 in a tabular format (with rows corresponding to implemention and columns corresponding to experiment setup (10 iterations, 50 iterations)). Discuss the run times and explaing the differences. \n",
    "\n",
    "Plot the pagerank values for the top 100 pages resulting from the 50 iterations run (using GraphX). Then plot the pagerank values for the same 100 pages that resulted from the 50 iterations run of your homegrown pagerank implemnentation.  Comment on your findings.  Have the top 100 ranked pages changed? Have the pagerank values changed? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 14.4: Criteo Phase 2 baseline\n",
    "\n",
    "\n",
    "SPECIAL NOTE:\n",
    "Please share your findings as they become available with class via the Google Group. You will get brownie points for this.  Once results are shared please use them and build on them.\n",
    "\n",
    "The Criteo data for this challenge is located in the following S3/Dropbox buckets:\n",
    "\n",
    "On Dropbox see:\n",
    "     https://www.dropbox.com/sh/dnevke9vsk6yj3p/AABoP-Kv2SRxuK8j3TtJsSv5a?dl=0\n",
    "\n",
    "Raw Data:  (Training, Validation and Test data)\n",
    "https://console.aws.amazon.com/s3/home?region=us-west-1#&bucket=criteo-dataset&prefix=rawdata/\n",
    "\n",
    "Hashed Data: Training, Validation and Test data in hash encoded (10,000 buckets) and sparse representation\n",
    "https://console.aws.amazon.com/s3/home?region=us-west-1#&bucket=criteo-dataset&prefix=processeddata/\n",
    "\n",
    "\n",
    "Using the training dataset, validation dataset and testing dataset in the Criteo bucket perform the following experiment:\n",
    "\n",
    "* write spark code (borrow from Phase 1 of this project) to train a logistic regression model with the following hyperparamters:\n",
    "  * Number of buckets for hashing: 1,000\n",
    "  * Logistic Regression: no regularization term\n",
    "  * Logistic Regression: step size = 10\n",
    "\n",
    "Report the AWS cluster configuration that you used and how long in minutes and seconds it takes to complete this job.\n",
    "\n",
    "Report in tabular form the AUC value (https://en.wikipedia.org/wiki/Receiver_operating_characteristic) for the Training, Validation, and Testing datasets.\n",
    "Report in tabular form  the logLossTest for the Training, Validation, and Testing datasets.\n",
    "\n",
    "Dont forget to put a caption on your tables (above each table)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 14.5: Criteo Phase 2 hyperparameter tuning\n",
    "\n",
    "SPECIAL NOTE:\n",
    "Please share your findings as they become available with class via the Google Group. You will get brownie points for this.  Once results are shared please used them and build on them.\n",
    " \n",
    "\n",
    "Using the training dataset, validation dataset and testing dataset in the Criteo bucket perform the following experiments:\n",
    "\n",
    "* write spark code (borrow from Phase 1 of this project) to train a logistic regression model with various hyperparamters. Do a gridsearch of the hyperparameter space and determine optimal settings using the validation set.\n",
    "\n",
    "* Number of buckets for hashing: 1,000, 10,000, .... explore different values  here\n",
    "* Logistic Regression: regularization term: [1e-6, 1e-3]  explore other  values here also\n",
    "* Logistic Regression: step size: explore different step sizes. Focus on a stepsize of 1 initially. \n",
    "\n",
    "Report the AWS cluster configuration that you used and how long in minutes and seconds it takes to complete this job.\n",
    "\n",
    "Report in tabular form and using heatmaps the AUC values (https://en.wikipedia.org/wiki/Receiver_operating_characteristic) for the Training, Validation, and Testing datasets.\n",
    "Report in tabular form and using heatmaps  the logLossTest for the Training, Validation, and Testing datasets.\n",
    "\n",
    "Dont forget to put a caption on your tables (above the table) and on your heatmap figures (put caption below figures) detailing the experiment associated with each table or figure (data, algorithm used, parameters and settings explored.\n",
    "\n",
    "Discuss the optimal setting to solve this problem  in terms of the following:\n",
    "* Features\n",
    "* Learning algortihm\n",
    "* Spark cluster\n",
    "\n",
    "Justiy your recommendations based on your experimental results and cross reference with table numbers and figure numbers. Also highlight key results with annotations, both textual and line and box based, on your tables and graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 14.6 Field-aware Factorization Machine FFM test on detecting malicious Web sites\n",
    "\n",
    "Download the Spark libFM from https://github.com/zhengruifeng/spark-libFM\n",
    "\n",
    "Run the FFM code on the hdfs://ns1/whale-tmp/url_combined dataset \n",
    "\n",
    "FFM sample code: https://github.com/zhengruifeng/spark-libFM/blob/master/src/main/scala/TestFM.scala\n",
    "\n",
    "on the following dataset:\n",
    "\n",
    "url_combined dataset is located at:\n",
    "\n",
    " http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/url_combined.bz2\n",
    "\n",
    "\n",
    "Report the AWS cluster configuration that you used and how long in minutes and seconds it takes to complete this job. Discuss the differences in the two factorizations. \n",
    "\n",
    "For some more background on the r detecting malicious Web sites dataset see the following:\n",
    "```\n",
    "The long-term goal of this research (and this dataset) is to construct a real-time system that uses machine learning techniques to detect malicious URLs (spam, phishing, exploits, and so on). To this end, we have explored techniques that involve classifying URLs based on their lexical and host-based features, as well as online learning to process large numbers of examples and adapt quickly to evolving URLs over time.\n",
    "\n",
    "The data set consists of about 2.4 million URLs (examples) and 3.2 million features.\n",
    "A label of +1 corresponds to a malicious URL and -1 corresponds to a benign URL.\n",
    "An anonymized 120-day subset of our ICML-09 data set.\n",
    "Data is encoded in SVM-ligth form\n",
    "Attack Label, URLs-features, HostID/Address features\n",
    "\n",
    "E.g, there are 835,764 unique Hostname-based features T\n",
    "To implement these features, they  use a bag-of-words representation\n",
    "of tokens in the URL, where ‘/’, ‘?’, ‘.’, ‘=’, ‘-’,\n",
    "and ‘ ’ are delimiters. We distinguish tokens that appear in\n",
    "the hostname, path, the top-level domain (TLD), primary\n",
    "domain name (the domain name given to a registrar), and\n",
    "last token of the path (to capture file extensions). Thus,\n",
    "‘com’ in the TLD position of a URL would be a different\n",
    "token from ‘com’ in other parts of the URL. We also use\n",
    "the lengths of the hostname and the URL as features. \n",
    "\n",
    "\n",
    "http://sysnet.ucsd.edu/projects/url/\n",
    "[JM09a]\n",
    "Justin Ma, Lawrence K. Saul, Stefan Savage, and Geoffrey M. Voelker. \n",
    "Identifying suspicious URLs: An application of large-scale online learning. \n",
    "In Proceedings of the Twenty Sixth International Conference on Machine Learning (ICML), pages 681-688, 2009.\n",
    "\n",
    "Source: [JM09a] https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/ref.html#JM09a\n",
    "```\n",
    "\n",
    "Preprocessing: The file \"url_original.tar.bz2\" contains a directory 121 days, in which the file \"FeatureTypes\" gives indices of real-valued features (other features are 0/1). The file \"url_combined.bz2\" combines all 121-day data into one file. See more details in this page.\n",
    "* of classes: 2\n",
    "* of data: 2,396,130\n",
    "* of features: 3,231,961\n",
    "\n",
    "Files:\n",
    "* url_combined.bz2\n",
    "* url_original.tar.bz2\n",
    "\n",
    "https://www.dropbox.com/s/yz8kcvzyyn4s7bb/url_combined.txt?dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 14.6.1  (OPTIONAL) Field-aware Factorization Machine  FFM comparison \n",
    "\n",
    "Using the following training data (where each record is row consisting of a user, item, rating):\n",
    "\n",
    "   https://www.dropbox.com/s/04rvxpawxelo6b0/test.data.txt?dl=0\n",
    " \n",
    "Run the following Field-aware Factorization Machine test (note the data may need to be reformatted and one-hot-encoded for this code to work):\n",
    "\n",
    "     https://github.com/zhengruifeng/spark-libFM/blob/master/src/main/scala/TestFM.scala\n",
    "\n",
    "with k (number of factors in the parameter matrix) set to 4.\n",
    "\n",
    "What does this model predict for the following test set:\n",
    "```\n",
    "user=3, item 7, rating=4\n",
    "user=1, item 2, rating=4\n",
    "user=6, item 3, rating=4\n",
    "user=7, item 4, rating=4\n",
    "```\n",
    "Report the predictions for each example and the mean squared error (MSE).\n",
    "\n",
    "Using the ALS algorithm (MLlib), with rank = 4, repeat the above experiment using the following code snippet: \n",
    "\n",
    "https://www.dropbox.com/s/vr3n41ngsnc8kqx/ALS-MLlib.ipynb?dl=0\n",
    "\n",
    "Report the predictions on the test set and the MSE. Discuss your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 14.7 Replicate Criteo Challenge winning solution\n",
    "\n",
    "Using the following as reference material (slides and code):\n",
    "\n",
    "3 Idiots’ Approach for Display Advertising Challenge, YuChin Juan, Yong Zhuang, and Wei-Sheng Chin, NTU CSIE MLGroup\n",
    "https://github.com/guestwalk/kaggle-2014-criteo \n",
    "http://www.csie.ntu.edu.tw/~r01922136/kaggle-2014-criteo.pdf\n",
    "\n",
    "\n",
    "and the Criteo data: The data for this challenge is located at:\n",
    "\n",
    "Raw Data:  (Training, Validation and Test data)\n",
    "https://console.aws.amazon.com/s3/home?region=us-west-1#&bucket=criteo-dataset&prefix=rawdata/\n",
    "\n",
    "Hashed Data: Training, Validation and Test data in hash encoded (10,000 buckets) and sparse representation\n",
    "https://console.aws.amazon.com/s3/home?region=us-west-1#&bucket=criteo-dataset&prefix=processeddata/\n",
    "\n",
    "\n",
    "Replicate (as close as possible) the winning submission for the Criteo. I.e., adapt their 2 step-approach of \n",
    "GBDT + Field-aware Factorization Machine (FFM). \n",
    "\n",
    "Report the AWS cluster configuration that you used and how long in minutes and seconds it takes to complete this job.\n",
    "\n",
    "Report in tabular form and using heatmaps the AUC values (https://en.wikipedia.org/wiki/Receiver_operating_characteristic) for the Training, Validation, and Testing datasets.\n",
    "Report in tabular form and using heatmaps  the logLossTest for the Training, Validation, and Testing datasets.\n",
    "\n",
    "Dont forget to put a caption on your tables (above the table) and on your heatmap figures (put caption below figures) detailing the experiment associated with each table or figure (data, algorithm used, parameters and settings explored.\n",
    "\n",
    "Discuss the optimal setting to solve this problem  in terms of the following:\n",
    "* Features\n",
    "* Learning algortihm\n",
    "* Spark cluster\n",
    "\n",
    "Justiy your recommendations based on your experimental results and cross reference with table numbers and figure numbers. Also highlight key results with annotations, both textual and line and box based, on your tables and graphs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW14.8 Heritage Healthcare Prize (OPTIONAL)\n",
    "\n",
    "The slides for Week 14 Live session contain background information for the HHH competition to predict the number of days a patient will spend in hospital.  Please review the slides. All the data, Spark code, R Code, documentation, and slides for HHH problem are located at: \n",
    "\n",
    "https://www.dropbox.com/sh/upt0j2q44ncrn1m/AAApdpXNYaEFy8KbMoE90-KSa?dl=0 \n",
    "\n",
    "In particular have a look at the following Spark/R Code:\n",
    "\n",
    "— https://www.dropbox.com/s/jltk9z7jkc1o856/mainDriver.R?dl=0\n",
    "- Spark SQL-Based plus Pipeline\n",
    "* http://nbviewer.jupyter.org/urls/dl.dropbox.com/s/5gwy8w4rcxrseey/HeritageHealthPrizeUnitTestNotebook_SQL_FINAL.ipynb \n",
    "— Spark MapReduce based pipeline\n",
    "* http://nbviewer.jupyter.org/urls/dl.dropbox.com/s/pubt4mgciqyylxs/HeritageHealthPrizeUnitTestNotebook_ORIGINAL_FINAL.ipynb   \n",
    "\n",
    "Improve the predictive quality of your system through activities such as (see both Spark notebooks for inspiration):\n",
    "\n",
    "* new features\n",
    "* feature transformations\n",
    "* data sampling/deletion\n",
    "* third party data\n",
    "* learning algorithms\n",
    "* hyperparameter tuning\n",
    "* etc.\n",
    "\n",
    "\n",
    "State your assumptions (Training data, validation data, held out test data). Report your experimental setup and experimental times, and evaluation metrics versus the baseline submission code provided above and discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==================END HW ==================\n",
    "==========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
